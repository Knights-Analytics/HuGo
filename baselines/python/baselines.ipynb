{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "# from Pooling import Pooling\n",
    "from transformers import AutoTokenizer\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import psutil\n",
    "import memory_profiler as mem_profile\n",
    "from pprint import pprint\n",
    "import tracemalloc\n",
    "\n",
    "TEXT_COL = 5\n",
    "sentence = \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mem_usage():\n",
    "    mem_usage = mem_profile.memory_usage()[0]\n",
    "    # print(f\"Final memory usage: {mem_usage:.2f} MB\")\n",
    "    return f\"{mem_usage:.2f} MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(tokens, inputs):\n",
    "    output_vectors = []\n",
    "    attention_mask = torch.tensor(inputs['attention_mask'])\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(tokens.size()).to(tokens.dtype)\n",
    "    )\n",
    "    sum_embeddings = torch.sum(tokens * input_mask_expanded, 1)\n",
    "    sum_mask = input_mask_expanded.sum(1)\n",
    "    sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "\n",
    "    output_vectors.append(sum_embeddings / sum_mask)\n",
    "    \n",
    "    return output_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # initialize model and load data\n",
    "    initialize_start = time.time()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"KnightsAnalytics/all-MiniLM-L6-v2\")\n",
    "    onnx_model_path = \"model.onnx\"\n",
    "    session = ort.InferenceSession(onnx_model_path)\n",
    "    data = pd.read_csv(\"/home/testuser/repositories/hugot/text_data.csv\", header=None)\n",
    "    data = data[:5000]\n",
    "    initialize_time = time.time() - initialize_start\n",
    "\n",
    "    metrics = {}\n",
    "    NUM_ITERS = 1\n",
    "    time_per_iter = []\n",
    "    print('Starting loop')\n",
    "\n",
    "    text_embeddings = []\n",
    "\n",
    "    # data loop\n",
    "    for i in range(NUM_ITERS):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for index in tqdm(range(len(data))):\n",
    "            row = data.iloc[index]\n",
    "            text = row[TEXT_COL]\n",
    "            inputs = tokenizer(text, return_tensors=\"np\")\n",
    "            onnx_inputs = {\n",
    "                session.get_inputs()[0].name: inputs['input_ids'],\n",
    "                session.get_inputs()[1].name: inputs['attention_mask'],\n",
    "                session.get_inputs()[2].name: inputs['token_type_ids']\n",
    "            }\n",
    "            try:\n",
    "                outputs = session.run(None, onnx_inputs)\n",
    "                tokens = torch.tensor(outputs[0])\n",
    "                sentence_embedding = mean_pooling(tokens, onnx_inputs)\n",
    "                text_embeddings.append(sentence_embedding[0][0].tolist())\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        iter_duration = time.time() - start_time\n",
    "        time_per_iter.append(iter_duration)\n",
    "        print(f\"Iteration {i+1} took {iter_duration:.2f} seconds\")\n",
    "        \n",
    "\n",
    "\n",
    "    avg_time = sum(time_per_iter) / NUM_ITERS\n",
    "    metrics['startup time'] = initialize_time\n",
    "    metrics['time per iteration'] = time_per_iter\n",
    "    metrics['average runtime'] = avg_time\n",
    "\n",
    "    print(\"Metrics:\")\n",
    "    print(metrics)\n",
    "    torch.set_printoptions(precision=6, sci_mode=False)\n",
    "\n",
    "    return text_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 137.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 took 7.27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 121.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 took 8.23 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 130.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 took 7.65 seconds\n",
      "Metrics:\n",
      "{'startup time': 8.713757514953613, 'time per iteration': [7.273473501205444, 8.230931282043457, 7.652797222137451], 'average runtime': 7.719067335128784}\n",
      "iteration used 464.18289852142334 MB of memory\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Run baseline code\n",
    "###\n",
    "tracemalloc.start()\n",
    "\n",
    "main()\n",
    "print(f\"iteration used {tracemalloc.get_traced_memory()[1] / 1024 / 1024} MB of memory\")\n",
    "\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 73.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 took 1.37 seconds\n",
      "Metrics:\n",
      "{'startup time': 3.891197919845581, 'time per iteration': [1.37239670753479], 'average runtime': 1.37239670753479}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"output.csv\"\n",
    "\n",
    "text_embeddings = main()\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    \n",
    "    # Write each row in the array to the CSV file\n",
    "    for row in text_embeddings:\n",
    "        csvwriter.writerow(row)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugot_baselines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
